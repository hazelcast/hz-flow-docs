= Observability
:description: '{short-product-name} automates API integration, and provides rich data discovery, so you can spend less time plumbing, and more time building.'

== Observing queries

As queries are executed by {short-product-name}, full call histories are captured and persisted.

This gives rich debugging tools to understand exactly how a query was executed,
which services were called and what they returned.

image:sequence-diagram.png[]

=== Configuring what's captured

The level of detail captured by {short-product-name} can be configured at startup, and entirely disabled, if desired.

When fully enabled, the following detail is captured and written to a database:

* Requests and responses sent to services, such as APIs and databases
* Metadata, such as URLs, response times, payload sizes, response codes and headers
* Message payloads for streaming event sources, such as message brokers
* Variations of the above data to build query plan charts visualized in the {short-product-name} UI

The following options can be passed as parameters or link:/docs/deploying/configuring-{short-product-name}#setting-as-environment-variables[configured as environment variables]
to control the level of data that is persisted.

|===
| Param | Description | Default

| `vyne.analytics.persistRemoteCallResponses`
| Defines if responses from remote queries are persisted to the database
| `true`

| `vyne.analytics.maxPayloadSizeInBytes`
| The max payload written to the database per response
| `2048`

| `vyne.analytics.persistRemoteCallMetadata`
| Should metadata (URL, response codes, call durations) be persisted
| `true`

| `vyne.analytics.persistResults`
| Should query results be persisted
| `true`
|===

== Performance metrics - Prometheus

{short-product-name} publishes metrics available for Prometheus to collect.

If {short-product-name} is connected to a Prometheus endpoint, performance data is made available in the endpoint's UI.

image:performance-metrics.png[Performance metrics]

=== Streaming queries

The following metrics are published for persistent queries (both streaming and request / response queries)

* Count of requests processed
* Processing duration
* Error counts

Prometheus can then provide this data as a histogram, providing min / max and averages.

=== Configuring Prometheus

An example Prometheus configuration is shown below:

[,yaml]
----
scrape_configs:
   - job_name: '{short-product-name} Stream Server Metrics'
     metrics_path: '/api/actuator/prometheus'
     scrape_interval: 3s
     static_configs:
#        172.17.0.1 is the ip address of localhost
#        from within docker
        - targets: ['172.17.0.1:9615']
          labels:
             application: '{short-product-name} - Stream Server'
   - job_name: '{short-product-name} Metrics'
     metrics_path: '/api/actuator/prometheus'
     scrape_interval: 3s
     static_configs:
        #        172.17.0.1 is the ip address of localhost
        #        from within docker
        - targets: ['172.17.0.1:9022']
          labels:
             application: '{short-product-name}'
----
